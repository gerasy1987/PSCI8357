---
title: "Observational Studies:<br>DiD/Panel"
subtitle: "PSCI 8357 - Stats II"
author: Georgiy Syunyaev
institute: "Department of Political Science, Vanderbilt University"
date: today
date-format: long
format: 
  revealjs:
    toc: true
    toc-depth: 2
    toc-title: "Plan"
    slide-number: c/t
    # preview-links: true
    embed-resources: true
    link-external-icon: true
    link-external-newwindow: true
    html-math-method: mathjax
    # logo: images/wzb_logo.png
    self-contained-math: true
    css: ../_supp/styles.css
    theme: [serif,"../_supp/custom.scss"]
    incremental: false
    self-contained: true
    citations-hover: true
    fragments: true
    # progress: true
    scrollable: false
    transition: fade
    reference-location: document
    slide-level: 3
    table-cap-location: bottom
    fig-cap-location: top
    include-before: [ '<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {enableAssistiveMml: false}});</script>']
fontsize: 26px
editor: source
aspectratio: 169
bibliography: ../_supp/psci8357.bib
---


### {data-visibility="hidden"}

\(
  \def\E{{\mathbb{E}}}
  \def\Pr{{\textrm{Pr}}}
  \def\var{{\mathbb{V}}}
  \def\cov{{\mathrm{cov}}}
  \def\corr{{\mathrm{corr}}}
  \def\argmin{{\arg\!\min}}
  \def\argmax{{\arg\!\max}}
  \def\qed{{\rule{1.2ex}{1.2ex}}}
  \def\given{{\:\vert\:}}
  \def\indep{{\mbox{$\perp\!\!\!\perp$}}}
  \def\notindep{{\mbox{$\centernot{\perp\!\!\!\perp}$}}}
\)

```{r}
#|  label: preamble
#|  include: false

# load necessary libraries
pacman::p_load(
  tidyverse,
  estimatr,
  future,
  future.apply,
  pbapply,
  patchwork,
  MASS,
  ggpubr
  # rsample
)

future::plan(multisession, workers = parallel::detectCores() - 2)

# set theme for plots
custom_theme <- theme(
  panel.background = element_rect(fill = "#f0f1eb", color = NA),
  plot.background = element_rect(fill = "#f0f1eb", color = NA),
  text = element_text(color = "#111111"),
  axis.text = element_text(color = "#111111"),
  axis.title = element_text(color = "#111111"),
  plot.title = element_text(color = "#111111", face = "bold"),
  plot.subtitle = element_text(color = "#111111"),
  legend.text = element_text(color = "#111111"),
  legend.title = element_text(color = "#111111"),
  legend.background = element_rect(fill = "#f0f1eb", color = NA)
)

thematic::thematic_on(bg = "#f0f1eb", fg = "#111111", accent = "#111111")
```

# Difference-in-Differences (DiD)

### Overview: Difference-in-Differences (DiD)

- Another popular identification strategy to relax [conditional ignorability (CIA)]{.highlight}.
- Applicable when we observe treatment and control groups before and after the treatment assignment.

. . .

- [Difference-in-Differences Estimator]{.highlight}:      
  $$
  \{\E(Y_{i1} \given G_i = 1)  - \E(Y_{i0} \given G_i = 1)\} - \{\E(Y_{i1} \given G_i = 0)  - \E(Y_{i0} \given G_i = 0)\}
  $$
  where second subscript is for time (post-treatment vs. pre-treatment)

. . .

- **Core assumption**: [Parallel Trends]{.highlight}
  
  - If the treatment group had not received the treatment, its outcome trend would have been the same as the trend of the outcome in the control group.
  - We can deal with time-invariant unmeasured confounders.

- [Goal]{.note}: 
  
  1. Understand what is the estimand in the DiD.
  2. Understand identification assumptions in the DiD.
  3. Understand estimation and inference (including linear regression).

### Difference-in-Differences Design

```{r}
#| label: did_estimator
#| fig-align: center
#| fig-width: 10
#| fig-height: 7

df <- data.frame(
  group = rep(c("Control", "Treatment", "Counterfactual"), each = 2),
  time = rep(c(0, 1), 3),
  outcome = c(
    1,   1.2,  # Control group (before -> after)
    2,   3,    # Treatment group (before -> after)
    2,   2.2   # Counterfactual (parallel shift of Control)
  )
)

ggplot(df, aes(x = time, y = outcome, color = group, linetype = group)) +
  # Draw lines and points
  geom_line(size = 1) +
  geom_point(size = 3, fill = "white") +
  
  scale_color_manual(
    name = "Trends",
    values = c("Control" = "#689d6a",
               "Counterfactual" = "#cc241d",
               "Treatment" = "#cc241d"),
    labels = c("Control Group",
               "Counterfactual for Treatment Group",
               "Treatment Group")
  ) +
  scale_linetype_manual(
    name = "Trends",
    values = c("Control" = "solid",
               "Counterfactual" = "dotted",
               "Treatment" = "solid"),
    labels = c("Control Group",
               "Counterfactual for Treatment Group",
               "Treatment Group")
  ) +
  
  scale_x_continuous(
    breaks = c(0, 1),
    labels = c("t = 0\n(before)", "t = 1\n(after)"),
    limits = c(-0.5,1.5)
  ) +
  annotate("segment", 
           x = 1.05, xend = 1.05, 
           y = 2.2,  yend = 3,
           arrow = arrow(angle = 90, ends = "both", length = unit(0.15, "cm")), 
           color = "black") +
  annotate("text", size = 5,
           x = 1.07, y = (2.2 + 3)/2, 
           label = "DiD estimate", 
           hjust = 0.0, vjust = 0.5) +
  labs(x = NULL, y = "Outcome") +
  theme_bw(base_size = 20) +
  theme(legend.position = "bottom",
        axis.text.y = element_blank(),
        axis.text.x = element_text(size = 18),
        panel.grid.minor = element_blank()) +
  custom_theme

```

## Classic Example

### Example: Minimum Wage and Employment

<br><br>

- **Question**: Do higher minimum wages decrease employment?

. . .

- @card1994minimum consider impact of New Jersey's 1992 minimum wage increase from \$4.25 to \$5.05 per hour

. . .

- Compare employment in 410 fast-food restaurants in New Jersey and eastern Pennsylvania before and after the rise

. . .

- Data: Two waves of survey on wages and employment
  
  - **Wave 1 ($t = 0$)**: March 1992, one month before the minimum wage increase
  - **Wave 2 ($t = 1$)**: December 1992, eight months after the increase

### Location of Restaurants

![](../_images/card_krueger_1994.png){width=90% fig-align="center"}

### Wages Before and After Rise in Minimum Wage

```{r}
#| label: card_krueger_hists
#| fig-align: center
#| fig-width: 14
#| fig-height: 8

card_krueger_1994_mod <- read_rds("../_data/card_krueger_mod.rds")

hist_before <-
  card_krueger_1994_mod |>
  filter(observation == "February 1992") |>
  ggplot(aes(wage_st, fill = state)) +
  geom_histogram(
    aes(
      y = c(
        ..count..[..group.. == 1] / sum(..count..[..group.. == 1]),
        ..count..[..group.. == 2] / sum(..count..[..group.. == 2])
      ) *
        100
    ),
    alpha = 0.8,
    position = "dodge",
    bins = 23
  ) +
  labs(
    title = "February 1992",
    x = "Wage range",
    y = "Percent of stores",
    fill = ""
  ) +
  scale_x_continuous(limits = c(4, 6.5)) +
  scale_fill_manual(
    values = c("Pennsylvania" = "#689d6a", "New Jersey" = "#cc241d")
  ) +
  theme_bw(base_size = 20) +
  custom_theme

hist_after <-
  card_krueger_1994_mod |>
  filter(observation == "November 1992") |>
  ggplot(aes(wage_st, fill = state)) +
  geom_histogram(
    aes(
      y = c(
        ..count..[..group.. == 1] / sum(..count..[..group.. == 1]),
        ..count..[..group.. == 2] / sum(..count..[..group.. == 2])
      ) *
        100
    ),
    alpha = 0.8,
    position = "dodge",
    bins = 15
  ) +
  labs(
    title = "November 1992",
    x = "Wage range",
    y = "Percent of stores",
    fill = ""
  ) +
  scale_x_continuous(limits = c(4, 6.5)) +
  scale_fill_manual(
    values = c("Pennsylvania" = "#689d6a", "New Jersey" = "#cc241d")
  ) +
  theme_bw(base_size = 20) +
  custom_theme

hist_before +
  hist_after +
  plot_layout(ncol = 2, guides = "collect", axis_titles = "collect") &
  theme(legend.position = "bottom")

```

## Identification

### Basic Setup for DiD

- **Data structure**:
    
    - Two waves of randomly sampled cross-sectional observations.
    - Either [panel]{.highlight} or [repeated cross sections]{.highlight}.

- **Cross-sectional units**: $i \in \{1, \ldots, n\}$

- **Time periods**: $t \in \{0 \text{ (pre-treatment)}, 1 \text{ (post-treatment)}\}$

- **Group indicator**:  

  $$
  G_i = \begin{cases}
  1 & \text{(treatment group)} \\
  0 & \text{(control group)}
  \end{cases}
  $$

- **Treatment indicator:** $T_{it} \in \{0,1\}$

. . .

- **Units in the treatment group receive treatment in $t=1$:**

| **Group**                           | **Pre-Period ($t = 0$)**         | **Post-Period ($t = 1$)**         |
|-------------------------------------|:-------------------------:|:--------------------------:|
| **$G_i = 1$ (treatment group)**     | $T_{i0} = 0$ (untreated)      | $T_{i1} = 1$ (treated)         |
| **$G_i = 0$ (control group)**       | $T_{i0} = 0$ (untreated)      | $T_{i1} = 0$ (untreated)       |


### Setup: Potential Outcomes and Estimand

- **Potential outcomes** $Y_{it}(t)$:

    - $Y_{it}(0)$: potential outcome for unit $i$ in period $t$ when not treated
    - $Y_{it}(1)$: potential outcome for unit $i$ in period $t$ when treated

- **Causal effect** for unit $i$ at time $t$ is  

  $$
  \tau_{it} = Y_{it}(1) - Y_{it}(0)
  $$

- **Observed outcomes** $Y_{it}$ are realized as  
  
  $$
  Y_{it} = Y_{it}(0)(1 - T_{it}) + Y_{it}(1) T_{it}
  $$

  - Since $T_{i1} = G_i$ in the post-treatment period, we can also write  
  
    $$
    Y_{i1} = Y_{i1}(0) (1 - G_i) + Y_{i1}(1) G_i
    $$

- **Estimand:** [_ATT_ in the post-treatment period]{.highlight}
  
$$
\tau_{ATT} = \E[Y_{i1}(1)-Y_{i1}(0) \given G_i = 1] = \E[Y_{i1}(1) \given G_i=1] - \textcolor{#cc241d}{\E[Y_{i1}(0) \given G_i=1]}
$$

### Identification Strategies

<br>

- **Estimand:** [_ATT_ in the post-treatment period]{.highlight}
  
$$
\tau_{ATT} = \E[Y_{i1}(1)-Y_{i1}(0) \given G_i = 1] = \E[Y_{i1}(1) \given G_i=1] - \textcolor{#cc241d}{\E[Y_{i1}(0) \given G_i=1]}
$$

<br>

|                                | **Pre-Period ($t=0$)**               | **Post-Period ($t=1$)**               |
|--------------------------------|:---------------------------:|:--------------------------:|
| **$G_i = 1$ (treatment group)**  | $\E[Y_{i0}(0) \given G_i=1]$             | $\E[Y_{i1}(1) \given G_i=1]$              |
| **$G_i = 0$ (control group)**    | $\E[Y_{i0}(0) \given G_i=0]$             | $\E[Y_{i1}(0) \given G_i=0]$              |


- [Problem]{.note}:

    - Missing potential outcome: $\color{#cc241d}{\E[Y_{i1}(0) \given G_i=1]}$

    - What is the average post-period outcome for the treated group in the absence of the treatment?

### Strategy 1: Before vs. After

<br>

|                                | **Pre-Period ($t=0$)**               | **Post-Period ($t=1$)**               |
|--------------------------------|:---------------------------:|:--------------------------:|
| **$G_i = 1$ (treatment group)**  | $\textcolor{#458588}{\E[Y_{i0}(0) \given G_i=1]}$             | $\textcolor{#458588}{\E[Y_{i1}(1) \given G_i=1]}$              |
| **$G_i = 0$ (control group)**    | $\E[Y_{i0}(0) \given G_i=0]$             | $\E[Y_{i1}(0) \given G_i=0]$              |

<br>

- **Identification Strategy**: [Before vs. After]{.highlight}

  - Assume [No Time Trend]{.highlight} (No change in average potential outcome over time)

$$
\textcolor{#cc241d}{\E[Y_{i1}(0) \given G_i=1]} = \textcolor{#458588}{\E[Y_{i0}(0)|G_i=1]}
$$

. . .

- **Estimator**:

$$
\widehat{\tau}_{ATT} = \textcolor{#458588}{\E[Y_{i1}|G_i=1] - \E[Y_{i0}|G_i=1]}
$$

### Strategy 1: Before vs. After

```{r}
#| label: before_after_estimator
#| fig-align: center
#| fig-width: 9
#| fig-height: 7

df <- data.frame(
  group = rep(c("Treatment", "Counterfactual"), each = 2),
  time = rep(c(0, 1), 2),
  outcome = c(
    2,   3,    # Treatment group (before -> after)
    2,   2    # Counterfactual (parallel shift of Control)
  )
)

ggplot(df, aes(x = time, y = outcome, color = group, linetype = group, shape = group)) +
  # Draw lines and points
  geom_line(size = 1) +
  geom_point(size = 3) +
  
  scale_color_manual(
    name = "Trends",
    values = c("Counterfactual" = "#cc241d",
               "Treatment" = "#cc241d"),
    labels = c("Counterfactual for Treatment Group",
               "Treatment Group")
  ) +
  scale_linetype_manual(
    name = "Trends",
    values = c("Counterfactual" = "dotted",
               "Treatment" = "solid"),
    labels = c("Counterfactual for Treatment Group",
               "Treatment Group")
  ) +
  scale_shape_manual(
    name = "Trends",
    values = c("Counterfactual" = 1,
               "Treatment" = 16),
    labels = c("Counterfactual for Treatment Group",
               "Treatment Group")
  ) +
  scale_x_continuous(
    breaks = c(0, 1),
    labels = c("t = 0\n(before)", "t = 1\n(after)"),
    limits = c(-0.5,1.5)
  ) +
  scale_y_continuous(
    limits = c(0.8,3.2)
  ) +
  annotate("segment", 
           x = 1.05, xend = 1.05, 
           y = 2,  yend = 3,
           arrow = arrow(angle = 90, ends = "both", length = unit(0.15, "cm")), 
           color = "black") +
  annotate("text", size = 5,
           x = 1.07, y = (2 + 3)/2, 
           label = "Before-After estimate", 
           hjust = 0.0, vjust = 0.5) +
  annotate("text", x = 1, y = 1.9,
           label = expression(E (Y[i1](0) ~ "|" ~ G[i]==1)),
           parse = TRUE, size = 5, hjust = 0.5) +
  annotate("text", x = 0, y = 1.9,
           label = expression(E (Y[i0] ~ "|" ~ G[i]==1)),
           parse = TRUE, size = 5, hjust = 0.5) +
  annotate("text", x = 1, y = 3.1,
           label = expression(E (Y[i1] ~ "|" ~ G[i]==1)),
           parse = TRUE, size = 5, hjust = 0.5) +
  labs(x = NULL, y = "Outcome") +
  theme_bw(base_size = 20) +
  theme(legend.position = "bottom",
        axis.text.y = element_blank(),
        axis.text.x = element_text(size = 18),
        panel.grid.minor = element_blank()) +
  custom_theme

```

### Strategy 2: Treated vs. Control in Post-Period

<br>

|                                | **Pre-Period ($t=0$)**               | **Post-Period ($t=1$)**               |
|--------------------------------|:---------------------------:|:--------------------------:|
| **$G_i = 1$ (treatment group)**  | $\E[Y_{i0}(0) \given G_i=1]$             | $\textcolor{#458588}{\E[Y_{i1}(1) \given G_i=1]}$              |
| **$G_i = 0$ (control group)**    | $\E[Y_{i0}(0) \given G_i=0]$             | $\textcolor{#458588}{\E[Y_{i1}(0) \given G_i=0]}$              |

<br>

- **Identification Strategy**: [Treated vs. Control in Post-Period]{.highlight}

  - Assume [Strict (Conditional)  Ignorability]{.highlight}

$$
\textcolor{#cc241d}{\E[Y_{i1}(0)|G_i=1]} = \textcolor{#458588}{\E[Y_{i1}(0)|G_i=0]}
$$

. . .

- **Estimator**:

$$
\widehat{\tau}_{ATT} = \textcolor{#458588}{\E[Y_{i1}|G_i=1] - \E[Y_{i1}|G_i=0]}
$$

### Strategy 2: Treated vs. Control in Post-Period

```{r}
#| label: dim_estimator
#| fig-align: center
#| fig-width: 9
#| fig-height: 7

df <- data.frame(
  group = rep(c("Treatment", "Counterfactual"), each = 2),
  time = rep(c(0, 1), 2),
  outcome = c(
    2,   3,    # Treatment group (before -> after)
    2,   1.2   # Counterfactual (parallel shift of Control)
  )
)

ggplot(df, aes(x = time, y = outcome, color = group, linetype = group, shape = group)) +
  # Draw lines and points
  geom_line(size = 1) +
  geom_point(size = 3, fill = "white") +
  
  scale_color_manual(
    name = "Trends",
    values = c("Counterfactual" = "#cc241d",
               "Treatment" = "#cc241d"),
    labels = c("Counterfactual for Treatment Group",
               "Treatment Group")
  ) +
  scale_linetype_manual(
    name = "Trends",
    values = c("Counterfactual" = "blank",
               "Treatment" = "solid"),
    labels = c("Counterfactual for Treatment Group",
               "Treatment Group")
  ) +
  scale_shape_manual(
    name = "Trends",
    values = c("Counterfactual" = 1,
               "Treatment" = 16),
    labels = c("Counterfactual for Treatment Group",
               "Treatment Group")
  ) +
  scale_x_continuous(
    breaks = c(0, 1),
    labels = c("t = 0\n(before)", "t = 1\n(after)"),
    limits = c(-0.5,1.5)
  ) +
  scale_y_continuous(
    limits = c(0.8,3.2)
  ) +
  annotate("segment", 
           x = 1.05, xend = 1.05, 
           y = 1.2,  yend = 3,
           arrow = ggplot2::arrow(angle = 90, ends = "both", length = unit(0.15, "cm")), 
           color = "black") +
  annotate("text", size = 5,
           x = 1.07, y = (1.2 + 3)/2, 
           label = "DiM estimate", 
           hjust = 0.0, vjust = 0.5) +
  annotate("text", x = 1, y = 1.1,
           label = expression(E (Y[i1] ~ "|" ~ G[i]==0) ~ "=" ~ E (Y[i1](0) ~ "|" ~ G[i]==1)),
           parse = TRUE, size = 5, hjust = 0.5) +
  annotate("text", x = 0, y = 1.9,
           label = expression(E (Y[i0] ~ "|" ~ G[i]==1)),
           parse = TRUE, size = 5, hjust = 0.5) +
  annotate("text", x = 1, y = 3.1,
           label = expression(E (Y[i1] ~ "|" ~ G[i]==1)),
           parse = TRUE, size = 5, hjust = 0.5) +
  labs(x = NULL, y = "Outcome") +
  theme_bw(base_size = 20) +
  theme(legend.position = "bottom",
        axis.text.y = element_blank(),
        axis.text.x = element_text(size = 18),
        panel.grid.minor = element_blank()) +
  custom_theme

```

### Identification Strategy: DiD

<br>

|                                | **Pre-Period ($t=0$)**               | **Post-Period ($t=1$)**               |
|--------------------------------|:---------------------------:|:--------------------------:|
| **$G_i = 1$ (treatment group)**  | $\textcolor{#458588}{\E[Y_{i0}(0) \given G_i=1]}$             | $\textcolor{#458588}{\E[Y_{i1}(1) \given G_i=1]}$              |
| **$G_i = 0$ (control group)**    | $\textcolor{#458588}{\E[Y_{i0}(0) \given G_i=0]}$             | $\textcolor{#458588}{\E[Y_{i1}(0) \given G_i=0]}$              |

. . .

<br>

- **Identification Strategy**: [Difference-in-Differences (DiD)]{.highlight}

  - Assume [Parallel Trends]{.highlight}:  

$$
\E\Bigl[ \textcolor{#cc241d}{Y_{i1}(0)} - \textcolor{#458588}{Y_{i0}(0)} \given G_i=1 \Bigr] = \E\Bigl[ \textcolor{#458588}{Y_{i1}(0) - Y_{i0}(0)} \given G_i=0 \Bigr]
$$

. . .

- [DiD Estimator]{.highlight}:

$$
\widehat{\tau}_{ATT} = \textcolor{#458588}{\Bigl\{ \E[Y_{i1}|G_i=1] - \E[Y_{i1}|G_i=0] \Bigr\} - \Bigl\{ \E[Y_{i0}|G_i=1] - \E[Y_{i0}|G_i=0] \Bigr\}}
$$

### DiD Estimator

```{r}
#| label: did_estimator_full
#| fig-align: center
#| fig-width: 10
#| fig-height: 7

df <- data.frame(
  group = rep(c("Control", "Treatment", "Counterfactual"), each = 2),
  time = rep(c(0, 1), 3),
  outcome = c(
    1,   1.2,  # Control group (before -> after)
    2,   3,    # Treatment group (before -> after)
    2,   2.2   # Counterfactual (parallel shift of Control)
  )
)

ggplot(df, aes(x = time, y = outcome, color = group, linetype = group, shape = group)) +
  # Draw lines and points
  geom_line(size = 1) +
  geom_point(size = 3, fill = "white") +
  
  scale_color_manual(
    name = "Trends",
    values = c("Control" = "#689d6a",
               "Counterfactual" = "#cc241d",
               "Treatment" = "#cc241d"),
    labels = c("Control Group",
               "Counterfactual for Treatment Group",
               "Treatment Group")
  ) +
  scale_linetype_manual(
    name = "Trends",
    values = c("Control" = "solid",
               "Counterfactual" = "dotted",
               "Treatment" = "solid"),
    labels = c("Control Group",
               "Counterfactual for Treatment Group",
               "Treatment Group")
  ) +
  scale_shape_manual(
    name = "Trends",
    values = c("Control" = 16,
               "Counterfactual" = 1,
               "Treatment" = 16),
    labels = c("Control Group",
               "Counterfactual for Treatment Group",
               "Treatment Group")
  ) +
  scale_x_continuous(
    breaks = c(0, 1),
    labels = c("t = 0\n(before)", "t = 1\n(after)"),
    limits = c(-0.5,1.5)
  ) +
  annotate("segment", 
           x = 1.05, xend = 1.05, 
           y = 2.2,  yend = 3,
           arrow = arrow(angle = 90, ends = "both", length = unit(0.15, "cm")), 
           color = "black") +
  annotate("text", size = 5,
           x = 1.07, y = (2.2 + 3)/2, 
           label = "DiD estimate", 
           hjust = 0.0, vjust = 0.5) +
  annotate("text", x = 1, y = 2.1,
           label = expression(E (Y[i1](0) ~ "|" ~ G[i]==1)),
           parse = TRUE, size = 5, hjust = 0.5) +
  annotate("text", x = 0, y = 1.9,
           label = expression(E (Y[i0] ~ "|" ~ G[i]==1)),
           parse = TRUE, size = 5, hjust = 0.5) +
  annotate("text", x = 0, y = 1.1,
           label = expression(E (Y[i0] ~ "|" ~ G[i]==0)),
           parse = TRUE, size = 5, hjust = 0.5) +
  annotate("text", x = 1, y = 1.3,
           label = expression(E (Y[i1] ~ "|" ~ G[i]==0)),
           parse = TRUE, size = 5, hjust = 0.5) +
  annotate("text", x = 1, y = 3.1,
           label = expression(E (Y[i1] ~ "|" ~ G[i]==1)),
           parse = TRUE, size = 5, hjust = 0.5) +
  labs(x = NULL, y = "Outcome") +
  theme_bw(base_size = 20) +
  theme(legend.position = "bottom",
        axis.text.y = element_blank(),
        axis.text.x = element_text(size = 18),
        panel.grid.minor = element_blank()) +
  custom_theme

```

### Identification with DiD

<br><br>

- Under the [parallel trends]{.highlight} assumption:

$$
\E[Y_{i1}(0) - Y_{i0}(0) \given G_i=1] = \E[Y_{i1}(0)-Y_{i0}(0) \given G_i=0]
$$

. . .

- Then the _ATT_ can be nonparametrically identified as:

$$
\tau_{ATT} = \Bigl\{ \E[Y_{i1} \given G_i=1]- \E[Y_{i1} \given G_i=0] \Bigr\} - \Bigl\{ \E[Y_{i0} \given G_i=1]- \E[Y_{i0} \given G_i=0] \Bigr\}
$$

### Identification with DiD: Proof

<br><br>

$$
\begin{aligned}
&\Bigl\{ \E[Y_{i1} \given G_i=1]- \E[Y_{i1} \given G_i=0] \Bigr\} - \Bigl\{ \E[Y_{i0} \given G_i=1]- \E[Y_{i0} \given G_i=0] \Bigr\} = \\
&\class{fragment}{= \Bigl\{ \E[Y_{i1}(1) \given G_i=1]- \E[Y_{i1}(0) \given G_i=0] \Bigr\}}\\ 
&\class{fragment}{\qquad- \Bigl\{ \E[Y_{i0}(0) \given G_i=1]- \E[Y_{i0}(0) \given G_i=0] \Bigr\} \quad (\because \text{ switching eq.})}  \\
&\class{fragment}{= \underbrace{\E[Y_{i1}(1) \given G_i=1] - \E[Y_{i1}(0) \given G_i=1]}_{= \ \tau_{ATT}} + \E[Y_{i1}(0) \given G_i=1] \qquad (\because \pm \E[Y_{i0}(0) \given G_i=1]) }\\
&\class{fragment}{\qquad - \E[Y_{i1}(0) \given G_i=0] - \E[Y_{i0}(0) \given G_i=1] + \E[Y_{i0}(0) \given G_i=0] }\\
&\class{fragment}{= \tau_{ATT} + \underbrace{\Bigl\{ \E[Y_{i1}(0)-Y_{i0}(0) \given G_i=1] - \E[Y_{i1}(0)-Y_{i0}(0) \given G_i=0] \Bigr\}}_{= \ 0 \text{ under parallel trends}} }\\
&\class{fragment}{= \tau_{ATT}  \qquad\qquad \qed}
\end{aligned}
$$

### Conditional DiD

- **Question**: What type of confounding does DiD make us robust to?
  
  :::fragment
  - Parallel trends hold if [unobserved confounding is time-invariant]{.highlight}.
  - Parallel trends are violated if there is [unobserved time-varying confounding]{.highlight}.
  :::

. . .

- [Idea]{.note}: Parallel trends may be more plausible with pre-treatment covariates:

$$
\E[Y_{i1}(0) - Y_{i0}(0) \given G_i=1, X_i=x] = \E[Y_{i1}(0)-Y_{i0}(0) \given G_i=0, X_i=x]
$$

  - [Intuition]{.note}: This assumes parallel trends within strata.

. . .

- Under the [conditional parallel trends]{.highlight} assumption, the _ATT_ is identified as:

$$
\begin{align*}
\tau_{ATT} &= \sum_{x} \Bigl[ \{ \E[Y_{i1} \given G_i=1, X_i=x]- \E[Y_{i1} \given G_i=0, X_i=x] \}\\
&\qquad - \{ \E[Y_{i0} \given G_i=1, X_i=x]- \E[Y_{i0} \given G_i=0, X_i=x] \}\Bigr] \Pr(X_i=x \given G_i=1)
\end{align*}
$$

### (Conditional) DiD in Different Confounding Scenarios

```{r}
#| label: biases_did
#| fig-align: center
#| fig-width: 12
#| fig-height: 7
#| echo: true
#| code-fold: true
#| output-location: fragment
#| code-line-numbers: "3-8|14,18-26|29-45"

set.seed(20250327)  # for reproducibility

# Simulation parameters
n <- 200            # total individuals (n/2 in treatment, n/2 in control)
tau <- 2            # true ATT (treatment effect in post period)
lambda <- 1         # common time effect
beta <- 2           # effect of confounder U on the outcome
error_sd <- 1       # standard deviation of error term

sims <-
  pbapply::pbreplicate(1000,
    {
      
      unit_U <- runif(n, 0, 0.5)

      sim_df <- 
        tibble(
          id = rep(1:n, each = 2),
          time = rep(c(0, 1), times = n),
          treat = as.numeric(id %in% sample(1:n, size = n/2, prob = 1 / 4 + unit_U)),
          ## time-invariant confounding
          U_ti = rep(unit_U, each = 2),
          ## time-varying confounding
          U_tv = if_else(treat == 1 & time == 1, U_ti + runif(1, 0, 0.25), U_ti),
          Y_ti = lambda * time + tau * (treat * time) + beta * U_ti + rnorm(n * 2, 0, error_sd),
          Y_tv = lambda * time + tau * (treat * time) + beta * U_tv + rnorm(n * 2, 0, error_sd)
        )
      
      # estimates for time-invariant case
      ti <-
        c(
          estimatr::lm_robust(Y_ti ~ treat * time, data = sim_df)$coefficients[["treat:time"]],
          estimatr::lm_robust(Y_ti ~ treat * time + U_ti, data = sim_df)$coefficients[["treat:time"]],
          estimatr::lm_robust(Y_ti ~ time, data = sim_df, subset = treat == 1)$coefficients[["time"]],
          estimatr::lm_robust(Y_ti ~ treat, data = sim_df, subset = time == 1)$coefficients[["treat"]]
        )
      
      # estimates for time-varying case
      tv <-
        c(
          estimatr::lm_robust(Y_tv ~ treat * time, data = sim_df)$coefficients[["treat:time"]],
          estimatr::lm_robust(Y_tv ~ treat * time + U_tv, data = sim_df)$coefficients[["treat:time"]],
          estimatr::lm_robust(Y_tv ~ time, data = sim_df, subset = treat == 1)$coefficients[["time"]],
          estimatr::lm_robust(Y_tv ~ treat, data = sim_df, subset = time == 1)$coefficients[["treat"]]
        )

      # Return a tibble with one row per scenario for this iteration
      expand_grid(
        scenario = c("Time-Invariant Confounding", "Time-Varying Confounding"),
        estimator = c("DiD", "Conditional DiD", "Before-After", "DiM")
      ) |>
        dplyr::mutate(
          est = c(ti, tv)
        )
    },
    simplify = FALSE,
    cl = 6
  ) |>
  bind_rows() |> 
  dplyr::mutate(
    correct = if_else((scenario == "Time-Invariant Confounding" & estimator == "DiD") | estimator == "Conditional DiD", 1, 0),
    estimator = factor(estimator, levels = c("Before-After", "DiM", "DiD", "Conditional DiD"))
  )


# Plot the Monte Carlo density estimates with ggplot2
ggplot(sims, aes(x = est, fill = factor(correct), color = factor(correct))) +
  ggdist::geom_dots() +
  # geom_density(alpha = 0.5) +
  geom_vline(xintercept = tau, linetype = "dashed", color = "black") +
  scale_color_manual(values = c("1" = "#689d6a", "0" = "#cc241d"), guide = "none") +
  scale_fill_manual(values = c("1" = "#689d6a", "0" = "#cc241d"), guide = "none") +
  facet_grid(scenario ~ estimator) +
  labs(x = "Estimate",
       y = "Density") +
  theme_bw(base_size = 20) +
  custom_theme

```

## Estimation and Inference

### Panel Data and Repeated Cross-Sectional Data

- [Panel data]{.highlight}: The same units are sampled at two time points.
- [Repeated cross-sectional data (RCS)]{.highlight}: Different units are sampled at different time points.

. . .

- [Examples]{.note}:

  - **Panel Data** [@anzia2012election]: Effect of elections on public employee salaries in Texas.
    
    - **Treatment**: Switch of school districts to on-cycle election timing in 2007.
    - **Outcome**: Average teacher salary.
    - **Results**: School districts that were forced to switch to on-cycle elections responded by granting significantly lower salary raises to teachers.

  - **RCS Data** [@malesky2014impact]: Examines the impact of electoral reforms on local public services in Vietnam.
    
    - **Treatment**: Stratified abolition of elected councils after 2009.
    - **Outcome**: Quality of local public services provision.
    - **Results**: Decentralization significantly improved public service delivery in policy areas important to central policy-makers.

### Plug-in Estimation for Panel Data

<br>

- **Panel data**: The same units are sampled at two time points.

- [Causal Estimand]{.highlight}:

  $$
  \tau_{ATT} = \left\{ \E [Y_{i1}|G_i=1]- \E [Y_{i1}|G_i=0]\right\} - \left\{ \E [Y_{i0}|G_i=1]- \E [Y_{i0}|G_i=0] \right\}
  $$

- [Plug-in estimator]{.highlight} (difference in difference-in-means):

  $$
  \begin{align*}
  \widehat{\tau}^{P}_{ATT} &\equiv \left\{\frac{1}{N_1}\sum_{i=1}^N G_iY_{i1} -
                \frac{1}{N_0}\sum_{i=1}^N (1-G_i)Y_{i1}\right\} -
                \left\{\frac{1}{N_1}\sum_{i=1}^N G_iY_{i0} -
                \frac{1}{N_0}\sum_{i=1}^N (1-G_i)Y_{i0} \right\}\\
      & =\left\{\frac{1}{N_1}\sum_{i=1}^N G_i\{Y_{i1} - Y_{i0} \} -
            \frac{1}{N_0}\sum_{i=1}^N (1-G_i)\{Y_{i1}-Y_{i0}\}\right\},
    \end{align*}
  $$

  where $N_1$ and $N_0$ are treated and control unit counts.

. . .

- **Inference**: Standard errors from standard difference in means.

### Example: Impact of Election Timing

<br>

```{r}
#| label: did_basic_panel
#| echo: true
#| eval: true
#| output-location: fragment
#| output: asis


anzia2012 <-
  readr::read_csv("../_data/anzia2012.csv") |>
  dplyr::filter(year %in% c(2006, 2007)) |>
  dplyr::group_by(district) |>
  dplyr::mutate(
    group = as.numeric(any(oncycle == 1 & year == 2007))
  ) |>
  dplyr::ungroup()

group_mn <-
  anzia2012 |>
  (\(.)
    list(
      Y_11 = mean(.$lnavgsalary_cpi[.$group == 1 & .$year == 2007]),
      Y_10 = mean(.$lnavgsalary_cpi[.$group == 1 & .$year == 2006]),
      Y_01 = mean(.$lnavgsalary_cpi[.$group == 0 & .$year == 2007]),
      Y_00 = mean(.$lnavgsalary_cpi[.$group == 0 & .$year == 2006]),

      n_Y_11 = sum(.$group == 1 & .$year == 2007),
      n_Y_10 = sum(.$group == 1 & .$year == 2006),
      n_Y_01 = sum(.$group == 0 & .$year == 2007),
      n_Y_00 = sum(.$group == 0 & .$year == 2006),

      var_Y_11 = var(.$lnavgsalary_cpi[.$group == 1 & .$year == 2007]),
      var_Y_10 = var(.$lnavgsalary_cpi[.$group == 1 & .$year == 2006]),
      var_Y_01 = var(.$lnavgsalary_cpi[.$group == 0 & .$year == 2007]),
      var_Y_00 = var(.$lnavgsalary_cpi[.$group == 0 & .$year == 2006])
    ))()

# did panel
panel_estimate <- (group_mn$Y_11 - group_mn$Y_10) - (group_mn$Y_01 - group_mn$Y_00)

# calculate standard errors
panel_se <- sqrt(
  group_mn$var_Y_11 / group_mn$n_Y_11 + 
  group_mn$var_Y_10 / group_mn$n_Y_10 + 
  group_mn$var_Y_01 / group_mn$n_Y_01 + 
  group_mn$var_Y_00 / group_mn$n_Y_00
)

panel_estimate
```

### Plug-in Estimation for Repeated Cross Sections

<br>

- **Repeated cross-sectional data (RCS)**: Different units are sampled at different time points

. . .

- Need to define group-time averages:

  $$
  \overline{Y}_{gt} = \frac{1}{N_{gt}} \sum_{i=1}^{N_{gt}} Y_{it}
  $$

  where $N_{gt}$ is the number of units in Group $G_i = g$ at time $t$.

- The plug-in estimator is then:

  $$
  \widehat{\tau}^{RC}_{ATT} = (\overline{Y}_{11} - \overline{Y}_{10}) - (\overline{Y}_{01} - \overline{Y}_{00})
  $$

. . .

- **Inference**: Standard errors from standard difference in means.

### Example: Minimum Wage Effect

![](../_images/card_krueger_1994_2.png){height="75%" fig-align="center"}

### Example: Impact of Recentralization

<br>

```{r}
#| label: did_basic_rcs
#| echo: true
#| eval: true
#| output-location: fragment
#| output: asis

malesky2014 <-
  readr::read_csv("../_data/malesky2014.csv") |>
  dplyr::filter(year >= 2008)

group_mn <-
  malesky2014 |>
  (\(.)
    list(
      Y_11 = mean(.$vpost[.$treatment == 1 & .$year == 2010]),
      Y_10 = mean(.$vpost[.$treatment == 1 & .$year == 2008]),
      Y_01 = mean(.$vpost[.$treatment == 0 & .$year == 2010]),
      Y_00 = mean(.$vpost[.$treatment == 0 & .$year == 2008]),

      n_Y_11 = sum(.$treatment == 1 & .$year == 2010),
      n_Y_10 = sum(.$treatment == 1 & .$year == 2008),
      n_Y_01 = sum(.$treatment == 0 & .$year == 2010),
      n_Y_00 = sum(.$treatment == 0 & .$year == 2008),

      var_Y_11 = var(.$vpost[.$treatment == 1 & .$year == 2010]),
      var_Y_10 = var(.$vpost[.$treatment == 1 & .$year == 2008]),
      var_Y_01 = var(.$vpost[.$treatment == 0 & .$year == 2010]),
      var_Y_00 = var(.$vpost[.$treatment == 0 & .$year == 2008])
    ))()

# did repeated cross-section
rcs_estimate <- (group_mn$Y_11 - group_mn$Y_10) - (group_mn$Y_01 - group_mn$Y_00)

# calculate standard errors
rcs_se <- sqrt(
  group_mn$var_Y_11 / group_mn$n_Y_11 + 
  group_mn$var_Y_10 / group_mn$n_Y_10 + 
  group_mn$var_Y_01 / group_mn$n_Y_01 + 
  group_mn$var_Y_00 / group_mn$n_Y_00
)


rcs_estimate
```

### Regression Estimator for RCS and Panel

<br>

- We can fit the following [interactive linear regression]{.highlight} in both RCS and Panel case: 
  $$
  Y_{it} =  \alpha + \theta\ G_i + \gamma\ \text{Post}_t + \tau\ G_i \times \text{Post}_t + \varepsilon_{it}
  $$

- We can show that $\widehat{\tau}_{OLS} = \widehat\tau_{ATT}$:

. . .


|                    | **Pre ($\text{Post}_t=0$)**                    | **Post ($\text{Post}_t = 1$)**         | **Post - Pre** |
|-----------------------|:-----------------------:|:----------------------:|:--------------------:|
| **Treated ($G_i=1$)**  | $\widehat\alpha + \widehat\theta$           | $\widehat\alpha+\widehat\theta+\widehat\gamma+\widehat\tau$ | $\widehat\gamma + \widehat\tau$ |
| **Control ($G_i=0$)**  | $\widehat\alpha$                           | $\widehat\alpha + \widehat\gamma$      | $\widehat\gamma$   |
| **Treated - Control**  | $\widehat\theta$                          | $\widehat\theta + \widehat\tau$        | $\widehat\tau$     |

. . .

- [Inference]{.highlight}:

  - Generally, "cluster robust" at the unit level, unless treatment is clustered at higher level.

  - Recent contributions on DID inference with few groups in @mackinnon2018wild and @ferman2015inference.

### Alternative Regression Estimator for RCS and Panel

<br><br><br>

- Two additional ways produce equivalent estimates in the two-period case without controls:

  :::incremental
  - [Two-Way Fixed Effects (TWFE) model]{.highlight}: $Y_{it} = \alpha_i + \lambda_t + \tau\ T_{it} + \varepsilon_{it}$
      
      - Means for control units *in the absence of treatment*: $\left(\alpha_{(0)} + \lambda_{(0)},\;\alpha_{(0)} + \lambda_{(1)} \right)$

      - Means for treated units: $\left(\alpha_{(1)} + \lambda_{(0)},\;\alpha_{(1)} + \lambda_{(1)} + \tau \right)$
  
  - [First-differences (FD) model]{.highlight} (only in panel case): $\Delta Y_i = \Delta \lambda + \tau\ G_i + \Delta \varepsilon_i$
  
      - Subtract pre-treatment from post-treatment outcomes to eliminate individual fixed effects $\alpha_i$, leaving $\tau$ as the coefficient on $G_i$.
  :::

### Estimation under Conditional Parallel Trends

<br><br>

- If you are assuming [conditional parallel trends]{.highlight} instead, then

  :::incremental
  1. **TWFE regression** that includes $X_{it} \times \text{Post}_k$ terms or first-differences ($\Delta Y_{i}$) regression that includes $X_i$’s.  
    
      - TWFE **must include interactions** with $\text{Post}_k$ (uninteracted $X_i$ will be partialled out by indiv. or group FEs).  
      - Specification or aggregation biases are a problem (similar to classic OLS results).

  2. **Inverse-propensity score weighting** using $e(X_i)$ with respect to $T_i$.

  3. **Matching on $X_i$ with respect to $T_i$** [@imai2023matching].
  :::

. . .

- [Note]{.note}: 

  - Conditional parallel trends requires overlap, like in standard regression setting.
  - Time-varying covariates ($\mathbf{X}_{it}$) should not include post-treatment variables!


### Example: Impact of Recentralization

<br>

```{r}
#| label: did_regression_rcs
#| echo: true
#| eval: true
#| output-location: column-fragment
#| output: asis

# did repeated cross-section
rcs_interactive <- 
  estimatr::lm_robust(
    vpost ~ treatment + post_treat + treatment*post_treat, 
    data = malesky2014,
    cluster = id_district)

rcs_twfe <- 
  estimatr::lm_robust(
    vpost ~ treatment:post_treat, 
    fixed_effects = ~ treatment + post_treat,
    data = malesky2014,
    cluster = id_district)

rcs_twfe2 <- 
  fixest::feols(vpost ~ treatment:post_treat | treatment + post_treat,
  data = malesky2014,
  cluster = ~id_district)

tibble(
  type = c("plug-in", "interactive", "twfe (estimatr)", "twfe (fixest)"),
  estimate = c(rcs_estimate, rcs_interactive$coefficients[[4]], 
                rcs_twfe$coefficients[[1]], rcs_twfe2$coefficients[[1]]),
  SE = c(rcs_se, rcs_interactive$std.error[[4]], 
          rcs_twfe$std.error[[1]], rcs_twfe2$se[[1]])
) |> 
  knitr::kable(
  digits = 3,
  align = "lcc",
  caption = "ATT Estimates of Effect of Recentralization"
) |>
  kableExtra::kable_minimal(font_size = 20)

```

### Example: Impact of Election Timing

<br>

```{r}
#| label: did_regression_panel
#| echo: true
#| eval: true
#| output-location: column-fragment
#| output: asis

# did repeated cross-section
panel_interactive <-
  estimatr::lm_robust(
    lnavgsalary_cpi ~ group * I(year == 2007),
    data = anzia2012,
    cluster = district
  )

panel_twfe <-
  estimatr::lm_robust(
    lnavgsalary_cpi ~ group:year,
    fixed_effects = ~ group + year,
    data = anzia2012,
    cluster = district
  )

panel_twfe2 <-
  fixest::feols(
    lnavgsalary_cpi ~ group:year | group + year,
    data = anzia2012,
    cluster = ~district
  )

panel_twfe_covars <-
  fixest::feols(
    lnavgsalary_cpi ~
      group:year +
        teachers_avg_yrs_exper +
        ami_pc +
        asian_pc +
        black_pc +
        hisp_pc |
        group + year,
    data = anzia2012,
    cluster = ~district
  )

tibble(
  type = c("plug-in", "interactive", "twfe (estimatr)", "twfe (fixest)", "twfe w/ covar's (fixest)"),
  estimate = c(
    panel_estimate,
    panel_interactive$coefficients[[4]],
    panel_twfe$coefficients[[1]],
    panel_twfe2$coefficients[[1]],
    panel_twfe_covars$coefficients[[6]]
  ),
  SE = c(
    panel_se,
    panel_interactive$std.error[[4]],
    panel_twfe$std.error[[1]],
    panel_twfe2$se[[1]],
    panel_twfe_covars$se[[6]]
  )
) |>
  knitr::kable(
    digits = 4,
    align = "lcc",
    caption = "ATT Estimates of Effect of Recentralization"
  ) |>
  kableExtra::kable_minimal(font_size = 20)

```

### DiD vs Lagged Dependent Variable

<br>

- Alternative to parallel trends is _a version_ of [ignorability]{.highlight}:

  $$
  Y_{i1}(0) \indep G_i \given Y_{i0}
  $$

  - Does **not** imply and is **not** implied by [parallel trends].
  - Benefit over parallel trends: It is scale-free. i.e. it does not depend on absolute levels.
  - Equivalent to parallel trends if 
    $$
    \E [Y_{i0} \given G_i = 1] = \E [Y_{i0} \given G_i = 0]
    $$

. . .

- **Different ideas about why there is selection**:
  
  - [DiD]{.highlight}: time-constant unmeasured confounder creates imbalance.
  - [LDV]{.highlight}: previous outcome directly affects treatment assignment.

### DiD/LDV bracketing

- **Estimator**: estimate CEF $\E[Y_{i1} \given Y_{i0}, G_i] = \alpha + \rho Y_{i0} + \tau G_i$

$$
\begin{align*}
\widehat{\tau}_{LDV} &= \underbrace{\frac{1}{N_1} \sum_{i=1}^N G_i Y_{i1} - \frac{1}{N_0} \sum_{i=1}^N (1 - G_i) Y_{i1}}_{\text{difference in post-period}} \\
&\qquad - \widehat{\rho}_{LDV} \underbrace{\Bigl(
\frac{1}{N_1} \sum_{i=1}^N G_i Y_{i0} - \frac{1}{N_0} \sum_{i=1}^N (1 - G_i) Y_{i0}
\Bigr)}_{\text{difference in pre-period}}
\end{align*}
$$

. . .

- If $0 \le \widehat{\rho}_{LDV} < 1$ ([stationarity]{.highlight}) and $G_i = 1$ has higher baseline outcomes than $G_i = 0$ ([stochastically dominates]{.highlight}) $\rightsquigarrow$ $\widehat{\tau}_{LDV} > \widehat{\tau}_{DiD}$ (and _vice versa_).

. . .

- [Bracketing relationship]{.highlight}: @ding2019bracketing show that if either **parallel trends or LDV** assumption hold

  $$
  \E[\widehat{\tau}_{LDV}] \ge \tau_{ATT} \ge \E[\hat{\tau}_{DiD}]
  $$

### Example: Minimum Wage Effect

<br>

![](../_images/ding_li.png){width="80%" fig-align="center"}

. . .

- Statinarity is satisfied and $F(y_i \given G_i = 0)$ stochastically dominates $F(y_i \given G_i = 1)$.

- $\widehat\tau_{DiD} = 2.446 > \widehat\tau_{LDV} = 0.302$.


## Diagnostics for Parallel Trends

### Parallel Trends Violations

<br>

1.[Selection and targeting]{.highlight}  
   
   - Treatment assignment may depend on time-varying factors.

   - [Examples]{.note}:
      
      - **Self-selection**: Participants in worker training programs experience a decrease in earnings before they enter the program.
      - **Targeting**: Policies may be targeted at units that are currently performing best (or worst).

. . .

2. [Compositional differences across time]{.highlight}
   
   - In repeated cross-sections, the composition of the sample may change between periods (e.g., due to migration).
   - This may confound any DID estimate since the "effect" may be attributable to a change in population.

### Parallel Trends Violations

3. [Long-term effects versus reliability]{.highlight}
   
   - The parallel trends assumption is most likely to hold over shorter time periods.
   - In the long run, many factors may confound the effect of treatment.

. . .

4. [Functional form dependence]{.highlight}
   
   - The magnitude or even the sign of the DiD effect may be sensitive to the functional form, especially when average outcomes for controls and treated differ substantially at baseline.

   - [Example]{.note}: Training program effects
      
      - Employment for the young increases from 20% to 30%; Employment for the old increases from 5% to 10%.
      
      - **Linear DiD effect is positive**: $(30 - 20) - (10 - 5) = 5\%$
   
      - But **log DiD changes in employment are negative**:
      $$
      [\log(30) - \log(20)] - [\log(10) - \log(5)] = \log(1.5) - \log(2) < 0
      $$

    - [Intuition]{.note}: DiD estimates may be more reliable if treated and control groups are _more similar at baseline_.


### Diagnostics for Parallel Trends

- [Idea]{.note} Check if the trends are parallel in the pre-treatment **periods** ($t = 0, -1, -2, ...$).

. . .

- **Approach 1**: [Visual Inspection ("Eyeballing")]{.highlight}
  
  - Check whether the trends are parallel between in $t <= 0$.

- **Approach 2**: [Formal tests]{.highlight}
  
  1. Suppose treatment occurs in $t = 0$: Use $t = -1$ as "placebo" treatment period, and re-estimate DiD.
  2. Estimate full $G \times t$ interactive model with $t = 0$ as reference category.
  3. @liu2024practical propose additional F- and t-tests implemented in `fect` package.

. . .

- [Note]{.note}: **this is only diagnostics**, not a direct test of the assumption!
  
  - E.g. in $t = -1$ we test
    
    $$
    \begin{align*}
      &\E[Y_{i,0}(0) - Y_{i, -1}(0) \given G_i=1] = \E[Y_{i, 0}(0)-Y_{i, -1}(0) \given G_i=0] \\
      &\Longleftrightarrow \E[Y_{i,0} - Y_{i, -1} \given G_i=1] = \E[Y_{i, 0} -Y_{i, -1} \given G_i=0]
    \end{align*}
    $$
  
  which is different from $\E[Y_{i,1}(0) - Y_{i, 0}(0) \given G_i=1] = \E[Y_{i, 1}(0)-Y_{i, 0}(0) \given G_i=0]$

- Do not forget about [pre-trend testing fallacy]{.highlight}: failure to reject the conventional null to test for parallel trends is problematic.

### "Eyeballing" Pre-Trends for Election Timing

```{r}
#| label: pre_trends_anzia
#| fig-align: center
#| fig-width: 14
#| fig-height: 9

anzia2012 <-
  readr::read_csv("../_data/anzia2012.csv") |>
  dplyr::filter(year <= 2007) |>
  dplyr::group_by(district) |>
  dplyr::mutate(
    group = as.numeric(any(oncycle == 1 & year == 2007))
  ) |>
  dplyr::ungroup()

anzia2012 |> 
  dplyr::filter(year >= 2006) |> 
  ggplot(aes(x = year, y = lnavgsalary_cpi, color = factor(group), fill = factor(group), group = factor(group))) +
  geom_vline(xintercept = 2006.5, color = "gray") +
  geom_point(position = position_jitter(width = 0.2, height = 0, seed = 123),
             shape = 16, alpha = 0.5, size = 1) +
  stat_summary(fun = "mean", geom = "line", aes(), size = 1) +
  stat_summary(fun = "mean", geom = "point", aes(group = group), size = 4, shape = 21, color = "white", stroke = 2) +
  scale_x_continuous(breaks = 2003:2007, limits = c(2002.5, 2007.5)) +
  scale_y_continuous(limits = c(10.3,11)) +
  scale_color_manual(values = c("#689d6a", "#cc241d"),
                     guide = "none") +
  scale_fill_manual(values = c("#689d6a", "#cc241d"),
                    guide = "none") +
  annotate("text", x = 2006.5, y = 10.7, label = "E[Y | G=0]", color = "#689d6a", size = 6) +
  annotate("text", x = 2006.5, y = 10.63, label = "E[Y | G=1]", color = "#cc241d", size = 6) +
  labs(x = "Year", y = "Y", color = NULL) +
  theme_bw(base_size = 20) +
  theme(panel.grid.minor = element_blank()) +
  custom_theme

```

### "Eyeballing" Pre-Trends for Election Timing

```{r}
#| label: pre_trends_anzia2
#| fig-align: center
#| fig-width: 14
#| fig-height: 9

anzia2012 |> 
  ggplot(aes(x = year, y = lnavgsalary_cpi, color = factor(group), fill = factor(group), group = factor(group))) +
  geom_vline(xintercept = 2006.5, color = "gray") +
  geom_point(position = position_jitter(width = 0.2, height = 0, seed = 123),
             shape = 16, alpha = 0.5, size = 1) +
  stat_summary(fun = "mean", geom = "line", aes(), size = 1) +
  stat_summary(fun = "mean", geom = "point", aes(group = group), size = 4, shape = 21, color = "white", stroke = 2) +
  scale_x_continuous(breaks = 2003:2007, limits = c(2002.5, 2007.5)) +
  scale_y_continuous(limits = c(10.3,11)) +
  scale_color_manual(values = c("#689d6a", "#cc241d"),
                     guide = "none") +
  scale_fill_manual(values = c("#689d6a", "#cc241d"),
                    guide = "none") +
  annotate("text", x = 2006.5, y = 10.7, label = "E[Y | G=0]", color = "#689d6a", size = 6) +
  annotate("text", x = 2006.5, y = 10.63, label = "E[Y | G=1]", color = "#cc241d", size = 6) +
  labs(x = "Year", y = "Y", color = NULL) +
  theme_bw(base_size = 20) +
  theme(panel.grid.minor = element_blank()) +
  custom_theme

```

### Placebo Test

<br>

```{r}
#| label: placebo_test1
#| echo: true
#| eval: true
#| output-location: column-fragment
#| code-line-numbers: "2-7"

out1 <-
  anzia2012 |> 
  dplyr::filter(year %in% c(2005, 2006)) |> 
  dplyr::mutate(oncycle_pl = as.numeric(group == 1 & year == 2006)) |> 
  estimatr::lm_robust(lnavgsalary_cpi ~ oncycle_pl, data = _, fixed_effects = ~ district + year,
  cluster = district, se_type = "CR0") |> 
  broom::tidy()

out2 <-
  anzia2012 |> 
  dplyr::filter(year %in% c(2004, 2005)) |> 
  dplyr::mutate(oncycle_pl = as.numeric(group == 1 & year == 2005)) |> 
  estimatr::lm_robust(lnavgsalary_cpi ~ oncycle_pl, data = _, fixed_effects = ~ district + year,
  cluster = district, se_type = "CR0") |> 
  broom::tidy()

bind_rows(out1, out2) |> 
  dplyr::select(term, estimate, std.error) |> 
  dplyr::mutate(term = c("2006-2005", "2005-2004")) |> 
  knitr::kable(
  digits = 3,
  align = "lcc",
  caption = "Placebo ATT Estimates"
) |>
  kableExtra::kable_minimal(font_size = 20)

```

### Placebo Test with `fect`

<br>

```{r}
#| label: placebo_test1_fect
#| code-fold: true
#| echo: true
#| fig-align: center
#| fig-width: 12
#| fig-height: 7

pacman::p_load(fect)

out.fect.p <- 
  anzia2012 |> 
  dplyr::filter(year >= 2005) |> 
  fect::fect(lnavgsalary_cpi ~ oncycle, data = _, index = c("district", "year"),
  force = "two-way", parallel = TRUE, se = TRUE, CV = 0,
  nboots = 200, placeboTest = TRUE, placebo.period = c(0))

plot(out.fect.p, 
      cex.text = 0.8, stats = c("placebo.p","equiv.p"), 
      main = "") + theme_bw(base_size = 20) + custom_theme

```

### Formal Test 2

<br>

```{r}
#| label: placebo_test2
#| code-fold: true
#| echo: true
#| fig-align: center
#| fig-width: 12
#| fig-height: 7

anzia2012 |> 
    dplyr::filter(year <= 2006) |> 
    dplyr::mutate(year = factor(year, levels = 2006:2003)) |> 
    estimatr::lm_robust(data = _, formula = lnavgsalary_cpi ~ year*group, cluster = district) |> 
    broom::tidy() |> 
    dplyr::filter(grepl(pattern = ":", x = term)) |> 
    dplyr::select(term, estimate, conf.low, conf.high) |> 
    bind_rows(tibble(term = "0", estimate = 0, conf.low = NA, conf.high = NA)) |> 
    dplyr::mutate(term = c(-1:-3,0)) |>    
    
    ggplot(aes(x = estimate, y = term)) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "gray") +
    geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = 0, color = "black") +
    geom_point(size = 3, fill = "black", color = "white", stroke = 2, shape = 21) +
    scale_x_continuous(limits = c(-.025,.025)) +
    # scale_y_discrete(breaks =) +
    labs(
      x = "Estimate (Year x Group Interaction)",
      y = "Pre-Treatment Time Period (Year)"
    ) +
    theme_bw(base_size = 20) +
    coord_flip() +
    custom_theme

```

## Sensitivity Analyses

### Sensitivity Analyses for Parallel Trends

<br>

- Recall that the DiD estimator can be expressed as:

  $$
  \begin{align*}
  \tau_{DiD}&= \underbrace{\E[Y_{i1}(1) \given G_i=1] - \E[Y_{i1}(0) \given G_i=1]}_{= \ \tau_{ATT}} \\
  &\qquad + \underbrace{\Bigl\{ \E[Y_{i1}(0)-Y_{i0}(0) \given G_i=1] - \E[Y_{i1}(0)-Y_{i0}(0) \given G_i=0] \Bigr\}}_{= \ 0 \text{ under parallel trends}}
  \end{align*}
  $$

. . .

- @rambachan2023more propose to [bound the bias term with pre-trend differences]{.highlight}:

  $$
  \begin{align*}
  &\E [Y_{i1} (0) - Y_{i0} (0) \given T_i = 1] - \E [Y_{i1} (0) - Y_{i0} (0) \given G_i = 0] \\
  &\quad = \phi \left( \E [Y_{i0} (0) - Y_{i,-1} (0) \given G_i = 1] - \E [Y_{i0} (0) - Y_{i,-1} (0) \given G_i = 0] \right),
  \end{align*}
  $$

  with $\phi \in [-b, b]$.

### Example: Impact of Election Timing

```{r}
#| label: sensitivity_fect
#| echo: true
#| eval: true
#| output-location: column-fragment
#| output: asis

pacman::p_load_gh("lzy318/HonestDiDFEct")

anzia2012 <-
  readr::read_csv("../_data/anzia2012.csv") |>
  dplyr::group_by(district) |>
  dplyr::mutate(
    group = as.numeric(any(oncycle == 1 & year == 2007))
  ) |>
  dplyr::ungroup()

ests <-
  estimatr::lm_robust(
    lnavgsalary_cpi ~ group * factor(year),
    fixed_effects = ~district,
    data = anzia2012
  )

vcov.hat.p <- ests$vcov[7:12, 7:12]

beta.hat.p <- unname(ests$coefficients[7:12])

HonestDiDFEct::createSensitivityResults_relativeMagnitudes(
  betahat = beta.hat.p,
  sigma = vcov.hat.p,
  numPrePeriods = 3,
  numPostPeriods = 3,
  l_vec = rep(1 / 3, 3),
  Mbarvec = seq(0, 1, by = 0.1)
) |>
  dplyr::select(Mbar, lb, ub) |>
  knitr::kable(
    digits = 3,
    align = "lcc",
    caption = "Sensitivity Analysis "
  ) |>
  kableExtra::kable_minimal(font_size = 20)

```

## Event Study (Post-Trends)

### Event Study (Post-Trends)

- The classic $2 \times 2$ DiD can be extended with pre- and post-trends to study effects of event.

. . .

- ["Event study"]{.highlight}: Estimate effects on different post-treatment periods

  $$
  Y_{it} = \alpha + \theta G_i + \sum_{k=1}^K \left( \phi_k \text{Post}^{k}_{t} + \textcolor{#cc241d}{\tau_k} \ G_i \times \text{Post}^{k}_{t} \right) + \varepsilon_{it},
  $$

  where $\tau_k$ captures effect of $k$ periods of exposure.

- Using pre- and post-trends $t = 0$ as reference period we can **evaluate parallel pre-trends**:

  $$
  Y_{it} = \alpha + \theta G_i + \sum_{j=-J}^{-1} \left( \rho_j \text{Pre}^{j}_{t} + \textcolor{#cc241d}{\pi_j} \ G_i \times \text{Pre}^{j}_{t} \right) + \sum_{k=1}^K \left( \phi_k \text{Post}^{k}_{t} + \textcolor{#cc241d}{\tau_k} \ G_i \times \text{Post}^{k}_{t} \right) + \varepsilon_{it}.
  $$

. . .

- [Note]{.note}: Using _only individual_ fixed effects is algebraically equivalent!


## Triple (...) Differences 😵‍💫

### Example: Cycling to School

<br><br>

- [Triple differences]{.highlight} or "difference in differences in differences":

  - Use a _placebo_ DiD to relax the parallel trends assumption!

. . .

::: {.columns}

::: {.column style="margin-top: 0em; width:60%;"}
- @muralidharan2017cycling: Effects of Cycling to School on educational outcomes among girls in India

  - Reform: Only in Bihar in 2007, all girls aged 14/15 are given a free bicycle.

  - **1st DID**: $G_i \in \{\text{girl, boy}\}$ and $T_i \in \{\text{2005, 2009}\}$ in Bihar.
  - **2nd DID (placebo)**: $G_i \in \{\text{girl, boy}\}$ and $T_i \in \{\text{2005, 2009}\}$ in Jharkhand.
:::

::: {.column style="margin-top: 2em; width:40%;"}

{{< video https://youtu.be/6nG63ISt_Ek?si=YhfNN90Sjki1cezn&t=26 width="450" height="250" >}}

:::

:::


### DDD Estimator

<br>

- The [DDD estimator]{.highlight}:

  $$
  \begin{align*}
  \widehat{\tau}_{DDD} =& \bigl\{ \widehat{\E}[Y_i \given \text{girl, 2005, B}] - \widehat{\E}[Y_i \given \text{girl, 2009, B}] \bigr\} \\
  &- \bigl\{ \widehat{\E}[Y_i \given \text{boy, 2005, B}] - \widehat{\E}[Y_i \given \text{boy, 2009, B}] \bigr\} \\
  &\quad - \Bigl(
  \bigl\{ \widehat{\E}[Y_i \given \text{girl, 2005, J}] - \widehat{\E}[Y_i \given \text{girl, 2009, J}] \bigr\} \\
  &\phantom{\quad - \Bigl(} - \bigl\{ \widehat{\E}[Y_i \given \text{boy, 2005, J}] - \widehat{\E}[Y_i \given \text{boy, 2009, J}] \bigr\}
  \Bigr)
  \end{align*}
  $$

- [Estimation]{.highlight}: Can use regression with a triple interaction, cluster at unit level again (villages in the example).

- [Intuition]{.note}: May eliminate time-varying confounding that is common across states (e.g., girls change more from grade 9 to 10 than boys).

### Example: Cycling to School

<br>

![](../_images/muralidharan_prakash_2017.png){width="75%" fig-align="center"}

### Extending DDD: Cycling to School

<br>

![](../_images/muralidharan_prakash_2017_2.png){width="75%" fig-align="center"}



## Continuous Treatment

### Continuous Treatment DID

- Suppose a slightly cleaner and more generic DGP:

  $$
  Y_{it} = \alpha_i + \lambda_t + \tau G_i \times f(T_i) \times \text{Post}_t + \epsilon_{it},
  $$

  meaning we have a pure control group ($G_i = 0$).

. . .

- **Potential outcomes**: $Y_{it}(d)$ for dose $T_i = d$.

- Revise the usual **parallel trend assumption** to identify the "level" _ATT_ effect:

  $$
  \E [Y_{i1}(0) - Y_{i0}(0) \given T_i = d] = \E [Y_{i1}(0) - Y_{i0}(0) \given T_i = 0],
  $$

  identifies $ATT(d) \equiv \E [Y_{i1}(d) - Y_{i0}(0) \given T_i = d]$.

. . .

- **Estimation**: First-difference regression with flexible specification for $T_{i}$:

$$
\Delta Y_i = \Delta \lambda + f(T_i) + \Delta \varepsilon_i.
$$

- @de2024difference use similar identifying assumption and an imputation-based estimator.


## Summary

### Takeaways

<br><br>

- [DiD]{.highlight}: An extremely popular strategy when there is longitudinal data (panel or repeated cross-sections) and the treatment is one-shot.

- [Parallel Trends Assumption]{.highlight} = If the treatment group had not received the treatment in the second period, its outcome trend would have been the same as the trend of the outcome in the control group.
  
  - We can deal with time-invariant unmeasured confounding.

- Always investigate the parallel trends assumption using pre-treatment data.

. . .

- We have focused on the basic DID design (the treatment is one-shot).

- Next we will generalize this to Staggered Adoption Design:
  
  - Diﬀerent units can receive the treatment in diﬀerent time periods

# Appendix {visibility="uncounted"}



### References {visibility="uncounted"}
